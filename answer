#!/usr/bin/python

# answer
# 11-411 NLP Spring 2013, Group 6

# Useful tools which should be pre-installed
import os, sys, errno
import re
import itertools
import nltk
from nltk.stem import PorterStemmer

# Import our modules from /modules
sys.path.append("modules")

import questionClassifier
import sourceContentSelector
from nltk_contrib.coref.resolve import BaselineCorefResolver

#entity_names = []
#
#if hasattr(t, 'node') and t.node:
#    if t.node == 'NE':
#        entity_names.append(' '.join([child[0] for child in t]))
#    else:
#        for child in t:
#            entity_names.extend(extract_entity_names(child))

def contains_negative(sent):
  return "no" in sent or "not" in sent or \
  "didn't" in sent or "did not" in sent

resolver = BaselineCorefResolver()

# picks the sentence that has the most keywords in common with the question
def answer(question, article):
    question = question.strip()
    question_type = questionClassifier.process(question)
    question = nltk.tokenize.word_tokenize(question)
    relevant = sourceContentSelector.process(question, article)

    relevant.sort(key = lambda s: s[1], reverse=True)
    top = relevant[0][0]
    if question_type == "BOOLEAN":
      if contains_negative(top):
        return "NO"
      else:
        return "YES"
    else:
      return top


if __name__ == '__main__':
  path_to_article = sys.argv[1]
  path_to_questions = sys.argv[2]

  # Pre-process article content.
  article = open(path_to_article).read()


  # Open the question file and start answering questions.
  for question in open(path_to_questions):
    print question
    print answer(question, article)
